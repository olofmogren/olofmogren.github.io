<!doctype html>
<html class="no-js">
  <head>
      
      <meta charset="utf-8">
      <title>Publications - Olof Mogren</title>
      <meta name="description" content="">
      <meta name="viewport" content="width=device-width">
      <link rel="stylesheet" href="/style.css">
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script>
        function showBibtex(event, text) {
          var el, x, y;

          el = document.getElementById('PopUp');
          if (window.event) {
            x = window.event.clientX + document.documentElement.scrollLeft
                + document.body.scrollLeft;
                y = window.event.clientY + document.documentElement.scrollTop +
                + document.body.scrollTop;
          }
          else {
            x = event.clientX + window.scrollX;
            y = event.clientY + window.scrollY;
          }
          x -= 2; y -= 2;
          y = y+15
          el.style.left = x + "px";
          el.style.top = y + "px";
          el.style.display = "block";
          document.getElementById('PopUpText').innerHTML = text;
       }
    </script>
  </head>
  <body class="home">

    <div class="bodydiv">
      <header id="header-waypoint">
        <nav id="stickyNav" class="sticky-nav">
          <div class="nametag">
            <div class="nametagsubdiv"><a href="http://mogren.one/" class="nametag"><h1 class="nametag">O<span style="font-size: 22px;">lof</span> M<span style="font-size: 22px;">ogren</span></h1></a></div>
            <div class="nametagsubscript"><span class="nametagsubscript">Senior machine learning researcher, PhD, at Research institutes of Sweden.</span></div>
          </div>
          <div id="groups" style="margin-right: 80px;">
            <div id="group1" style="z-index: 5;">
              <a href="/blog" style="color: #999;">Blog</a>
              <a href="/talks" style="color: #999;">Talks</a>
            </div>
            <div id="group2" style="z-index: 5;">
              <a href="/publications" style="color: #999;">Publications</a>
              <a href="/about" style="color: #999;">About</a>
            </div>
          </div>
        </nav>

      </header>

      <a class="github-ribbon" href="https://github.com/olofmogren">
        <img style="position: absolute; top: 0; right: 0; border: 0; z-index: 4;"
             src="/graphics/git-ribbon.png" alt="Fork me on GitHub">
      </a>

      <div id="PopUp" style="display: none; position: absolute; left: 100px; top: 50px; border: solid black 1px; padding: 10px; background-color: rgb(200,200,200); text-align: justify; font-size: 12px; min-width: 400px;">
        <pre id="PopUpText">TEXT</pre>
        <input name="close" type="button" value="Close" onclick="document.getElementById('PopUp').style.display = 'none';" />
      </div>

        <section>
        <div class="inner">
          <div class="block block-copy">
<h1>Publications</h1>
<p>This is a selection of my publications. Please also see my <a href="https://scholar.google.se/citations?user=m_n28oAAAAAJ&amp;hl=en">page on Google Scholar</a></p>          </div>
        </div>
      </section>

      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>Assisting Discussion Forum Users using Deep Recurrent Neural Networks</h2>
<img src="2016/assisting/rnn-recommendation.png" alt="LSTM Recommendation Model" style="float: right;" />
<p>We present a discussion forum assistant based on deep recurrent  neural networks (RNNs).
The assistant is trained to perform three different tasks when faced with a question from a user.
Firstly, to recommend related posts.
Secondly, to recommend other users that might be able to help.
Thirdly, it recommends other channels in the forum where people may discuss related topics.
Our recurrent forum assistant is evaluated experimentally by prediction accuracy for the end--to--end trainable parts, as well as by performing an end-user study.
We conclude that the model generalizes well, and is helpful for the users.
<br />
<em>To appear in: <a href="https://sites.google.com/site/repl4nlp2016/">Representation Learning for NLP, RepL4NLP, 2016</a></em><br />
<em>Jacob Hagstedt P Suorra, Olof Mogren</em><br /></p>
<a href="2016/assisting">More info</a>, <a href="2016/assisting/hagstedt2016assisting.pdf">PDF Fulltext</a>, <a href="javascript:void(null);" onclick="showBibtex(event, '@article{hagstedt2016assisting,\n  title={Assisting Discussion Forum Users using Deep Recurrent Neural Networks},\n  author={Hagstedt P Suorra, Jacob and Mogren, Olof},\n  journal={Representation Learning for NLP RepL4NLP at ACL 2016},\n  year={2016},\n  publisher={null}\n}\n')">bibtex</a>.
</div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>Extractive Summarization by Aggregating Multiple Similarities</h2>
<img src="../graphics/mogren_summarization.png" alt="Extractive Multi-Document Summarization" style="float: right;" />
<p>Many existing methods for extracting summaries rely on comparing the similarity of two sentences in some way. In this paper, we present new ways of measuring this similarity, based on sentiment analysis and continuous vector space representations, and show that combining these together with similarity measures from existing methods, helps to create better summaries. The finding is demonstrated with MULTSUM, a novel summarization method that uses ideas from kernel methods to combine sentence similarity measures. Submodular optimization is then used to produce summaries that take several different similarity measures into account. Our method improves over the state-of-the-art on standard benchmark datasets; it is also fast and scale to large document collections, and the results are statistically significant.<br /></p>
<!--**My contributions:** I am the main author of this work. I designed the study, performed the experiments, and wrote the manuscript.<br />//-->
<p><em>RANLP 2015, Hissar, Bulgaria, September 6th-11th</em><br />
<em>Olof Mogren, Mikael Kågebäck, Devdatt Dubhashi</em><br />
<a href="/summarization">More info</a>, <a href="/summarization/mogren2015extractive.pdf">PDF fulltext</a>, <a href="javascript:void(null);" onclick="showBibtex(event, '@article{mogrenextractive,\n  title={Extractive Summarization by Aggregating Multiple Similarities},\n  author={Mogren, Olof and Kågebäck, Mikael and Dubhashi, Devdatt},\n  journal={RECENT ADVANCES IN NATURAL LANGUAGE PROCESSING 2015},\n  pages={451}\n}')">bibtex</a>.</p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>Extractive Summarization using Continuous Vector Space Models</h2>
<p>A workshop paper showing preliminary results on multi-document summarization with continuous vector space models for sentence representation. The experiments were performed on opinionated online user reviews.<br /> </p>
<!--**My contributions:** I implemented the submodular optimization algorithm for sentence selection and created the setup for the experimental evaluation.<br />//-->
<p><em>2nd Workshop on Continuous Vector Space Models and their Compositionality CVSC 2014, Gothenburg Sweden</em><br />
<em>Mikael Kågebäck, Olof Mogren, Nina Tahmasebi, Devdatt Dubhashi</em><br />
<a href="/publications/2014/extractive">More info</a>, <a href="http://mogren.one/summarization/kageback2014extractive.pdf">PDF fulltext</a>, <a href="javascript:void(null);" onclick="showBibtex(event, '@inproceedings{kaageback2014extractive,\n  title={Extractive summarization using continuous vector space models},\n  author={Kågebäck, Mikael and Mogren, Olof and Tahmasebi, Nina and Dubhashi, Devdatt},\n  booktitle={Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC)@ EACL},\n  pages={31--39},\n  year={2014}\n}')">bibtex</a>.</p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<img src="../graphics/population_density_synthesis_200x418.png" alt="Extractive Multi-Document Summarization" style="float: right;">
<h2>Adaptive dynamics of realistic small-world networks</h2>
<p>Continuing in the steps of Jon Kleinberg's and others celebrated work on decentralized search in small-world networks, we conduct an experimental analysis of a dynamic algorithm that produces small-world networks. We find that the algorithm adapts robustly to a wide variety of situations in realistic geographic networks with synthetic test data and with real world data, even when vertices are uneven and non-homogeneously distributed.</p>
<p><em>European Conference on Complex Systems 2009</em><br />
<em>Olof Mogren, Oskar Sandberg, Vilhelm Verendel, Devdatt Dubhashi</em><br />
<a href="/networks">More info</a>, <a href="/networks/mogren2009adaptive.pdf">PDF fulltext</a>, <a href="javascript:void(null);" onclick="showBibtex(event, '@inproceedings{\nMogren2009,\nauthor={Mogren, Olof and Sandberg, Oskar and Verendel, Vilhelm and Dubhashi, Devdatt},\ntitle={Adaptive Dynamics of Realistic Small-World Networks},\nbooktitle={European Conference on Complex Systems 2009},\npages={12},\nabstract={Continuing in the steps of Jon Kleinberg’s and others celebrated work on decentralized search, we conduct an experimental analysis of destination sam- pling, a dynamic algorithm that produces small-world networks. We find that the algorithm adapts robustly to a wide variety of situations in realistic geographic net- works with synthetic test data and with real world data, even when vertices are unevenly and non-homogeneously distributed. We investigate the same algorithm in the case where some vertices are more popular destinations for searches than others, for example obeying power-laws. We find that the algorithm adapts and adjusts the networks ac- cording to the distributions, leading to improved per- formance. The ability of the dynamic process to adapt and create small worlds in such diverse settings suggests a possible mechanism by which such networks appear in nature.},\nyear={2009},\nkeywords={social networks, dynamics, algorithms, adaptive search},\n}\n')">bibtex</a>.</p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<img src="/graphics/illustrations/entitygraph_477x331.png" style="float: right;" />
<h2>Visions and open challenges for a knowledge-based culturomics</h2>
<p>A white paper outlining some ideas and challenges within the field of culturomics.<br /></p>
<!--**My contributions:** I wrote section 5, titled "Temporal Semantic Summarization", where I shared my views on possible research directions on generic multi-document summarization.<br />//-->
<p><em>International Journal on Digital Libraries, February 2015</em><br />
<em>Nina Tahmasebi, Lars Borin, Gabriele Capannini, Devdatt Dubhashi, Peter Exner, Markus Forsberg, Gerhard Gossen, Fredrik D. Johansson, Richard Johansson, Mikael Kågebäck, Olof Mogren, Pierre Nugues, Thomas Risse</em><br />
<a href="/publications/2015/visions">More info</a>, <a href="/publications/2015/visions/tahmasebi-visions-2015.pdf">PDF fulltext</a>, <a href="javascript:void(null);" onclick="showBibtex(event, '@article{tahmasebi2015visions,\n  title={Visions and open challenges for a knowledge-based culturomics},\n  author={Tahmasebi, Nina and Borin, Lars and Capannini, Gabriele and Dubhashi, Devdatt and Exner, Peter and Forsberg, Markus and Gossen, Gerhard and Johansson, Fredrik D and Johansson, Richard and Kågebäck, Mikael and Mogren, Olof and Nugues, Pierre and Risse, Thomas},\n  journal={International Journal on Digital Libraries},\n  volume={15},\n  number={2-4},\n  pages={169--187},\n  year={2015},\n  publisher={Springer}\n}\n')">bibtex</a>.</p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>Editing Simple Graphs</h2>
<img src="/graphics/wordgraph.png" alt="Extractive Multi-Document Summarization" style="float: right;" />
<p>Inspired by the word-co-occurrence graph from Wikipedia documents, this paper presents an FPT approach to cluster the words.<br /></p>
<!--**My contributions:**  I contributed to the study and the analysis, and to the writing of the manuscript, including illustrations.<br />//-->
<p><em>Journal of Graph Algorithms and Applications 18 (2014), 557-576</em><br />
<em>Peter Damaschke, Olof Mogren</em><br />
<a href="http://mogren.one/publications/2014/editing/">More info</a>, <a href="http://mogren.one/publications/2014/editing/damaschke2014editing.pdf">PDF fulltext</a>.</p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>Summarizing Online User Reviews Using Bicliques</h2>
<p>This paper presents an approach to summarize online user-reviews based on finding bicliques in the bipartite word-document graph.<br /></p>
<!--**My contributions:** I contributed to the study, did a substantial part of the experimental work, and contributed to the writing of the manuscript. <br />//-->
<p><em>Proceedings of SOFSEM 2016, LNCS 9587, pp 569-579.</em><br />
<em>Authors</em>: Azam Sheikh Muhammad, Peter Damaschke, Olof Mogren<br />
<em>Fulltext</em>: <a href="/summarization/muhammad2016summarizing.pdf">PDF</a>.</p>          </div>
        </div>
      </section>




        <section class="foot">
          <strong>Olof Mogren</strong> Research institutes of Sweden<br /><br />
          <a href="https://www.linkedin.com/in/olof-mogren-5392b452" title="Follow me on LinkedIn"><img src="/graphics/logos/linkedin_logo_42x40-white.png" alt="LinkedIn" /></a>&nbsp;<!--
          //--><a href="https://twitter.com/olofmogren" title="Follow me on Twitter"><img src="/graphics/logos/twitter_logo_49x40-white.png" alt="Twitter" /></a>&nbsp;<!--
          <a href="https://flokk.no/i/9be9cd2a348d" title="Follow me on Diaspora"><img src="/graphics/logos/diaspora_logo_42x40-white.png" alt="Diaspora" /></a>&nbsp;
          //--><a href="http://mogren.one/feed.xml" title="Follow my posts with RSS."><img src="/graphics/logos/rss.svg" style="width: 40px; height: 40px;" alt="Atom/RSS Feed" /></a>
        </section>

      </div><!-- main content //-->
    </div>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11067757; 
var sc_invisible=1; 
var sc_security="5e553e07"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="free web stats"
href="http://statcounter.com/free-web-stats/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11067757/0/5e553e07/1/" alt="free
web stats"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
  </body>
</html>
