<!doctype html>
<html class="no-js">
  <head>
      
      <meta charset="utf-8">
      <title>Neural Attention Models</title>
      <meta name="description" content="">
      <meta name="viewport" content="width=device-width">
      <link rel="stylesheet" href="/style.css">
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script>
        function showBibtex(event, text) {
          var el, x, y;

          el = document.getElementById('PopUp');
          if (window.event) {
            x = window.event.clientX + document.documentElement.scrollLeft
                + document.body.scrollLeft;
                y = window.event.clientY + document.documentElement.scrollTop +
                + document.body.scrollTop;
          }
          else {
            x = event.clientX + window.scrollX;
            y = event.clientY + window.scrollY;
          }
          x -= 2; y -= 2;
          y = y+15
          el.style.left = x + "px";
          el.style.top = y + "px";
          el.style.display = "block";
          document.getElementById('PopUpText').innerHTML = text;
       }
    </script>
  </head>
  <body class="home">

    <div class="bodydiv">
      <header id="header-waypoint">
        <nav id="stickyNav" class="sticky-nav">
          <div class="nametag">
            <div class="nametagsubdiv"><a href="http://mogren.one/" class="nametag"><h1 class="nametag">O<span style="font-size: 22px;">lof</span> M<span style="font-size: 22px;">ogren</span></h1></a></div>
            <div class="nametagsubscript"><span class="nametagsubscript">Senior machine learning researcher, PhD, at Research institutes of Sweden.</span></div>
          </div>
          <div id="groups" style="margin-right: 80px;">
            <div id="group1" style="z-index: 5;">
              <a href="/blog" style="color: #999;">Blog</a>
              <a href="/talks" style="color: #999;">Talks</a>
            </div>
            <div id="group2" style="z-index: 5;">
              <a href="/publications" style="color: #999;">Publications</a>
              <a href="/about" style="color: #999;">About</a>
            </div>
          </div>
        </nav>

      </header>

      <a class="github-ribbon" href="https://github.com/olofmogren">
        <img style="position: absolute; top: 0; right: 0; border: 0; z-index: 4;"
             src="/graphics/git-ribbon.png" alt="Fork me on GitHub">
      </a>

      <div id="PopUp" style="display: none; position: absolute; left: 100px; top: 50px; border: solid black 1px; padding: 10px; background-color: rgb(200,200,200); text-align: justify; font-size: 12px; min-width: 400px;">
        <pre id="PopUpText">TEXT</pre>
        <input name="close" type="button" value="Close" onclick="document.getElementById('PopUp').style.display = 'none';" />
      </div>

  <section>
<div class="inner">
<div class="block block-copy">


<h1>Neural Attention Models</h1>



<p>

<p>In artificial neural networks, attention models allow the system to focus on certain parts of the input. This has shown to improve model accuracy in a number of applications. In image caption generation, attention models help to guide the model towards the parts of the image currently of interest. In neural machine translation, the attention mechanism gives the model an alignment of the words between the source sequence and the target sequence.  In this talk, we'll go through the basic ideas and workings of attention models, both for recurrent networks and for convolutional networks. In conclusion, we will see some recent papers that applies attention mechanisms to solve different tasks in natural language processing and computer vision.<p><em>Mentioned papers</em></p><ul><li><a href="http://arxiv.org/abs/1409.0473" title="Bahdanau et.al.">Bahdanau et.al., Neural Machine Translation by Jointly Learning to Align and Translate</a></li><li><a href="http://arxiv.org/abs/1502.03044" title="Xu et.al.">Xu et.al., Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li><a href="http://arxiv.org/abs/1602.03001" title="Allamanis et.al.">Allamanis et.al., A Convolutional Attention Network for Extreme Summarization of Source Code</a></li></ul><p><em>Other related papers</em></p><ul><li><a href="http://arxiv.org/abs/1502.04623" title="Gregor et.al.">Gregor et.al., DRAW: A Recurrent Neural Network For Image Generation</a></li><li><a href="http://arxiv.org/abs/1506.03340" title="Hermann et.al.">Hermann et.al., Teaching Machines to Read and Comprehend</a></li><li><a href="http://arxiv.org/abs/1406.1078" title="Cho">Cho, et.al., Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a></li></ul><p><em>Links</em></p><ul><li><a href="https://re-work.co/blog/deep-learning-ilya-sutskever-google-openai" title="Ilya Sutskever Interview">Interview with Ilya Sutskever</a></li></ul></p>

</p>

<p><a href="/talks/slides/mogren-2016-02-18-ml-seminar-attention.pdf">Slides (PDF)</a></p>

<p>

<a href="http://www.cse.chalmers.se/research/lab/seminars/">

<em>Talk, Chalmers Machine Learning Seminars</em>

</a>

<br />
<em>Olof Mogren</em><br />
</p>
</div>
</div>
</section>

<section>
<div class="inner">
<div class="block block-copy">
<div id="disqus_thread"></div>
<script>

/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
  *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
  /*
  var disqus_config = function () {
  this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
  };
  */
  (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//mogren-one.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</div>
</section>

<script id="dsq-count-scr" src="//mogren-one.disqus.com/count.js" async></script>




        <section class="foot">
          <strong>Olof Mogren</strong> Research institutes of Sweden<br /><br />
          <a href="https://www.linkedin.com/in/olof-mogren-5392b452" title="Follow me on LinkedIn"><img src="/graphics/logos/linkedin_logo_42x40-white.png" alt="LinkedIn" /></a>&nbsp;<!--
          //--><a href="https://twitter.com/olofmogren" title="Follow me on Twitter"><img src="/graphics/logos/twitter_logo_49x40-white.png" alt="Twitter" /></a>&nbsp;<!--
          <a href="https://flokk.no/i/9be9cd2a348d" title="Follow me on Diaspora"><img src="/graphics/logos/diaspora_logo_42x40-white.png" alt="Diaspora" /></a>&nbsp;
          //--><a href="http://mogren.one/feed.xml" title="Follow my posts with RSS."><img src="/graphics/logos/rss.svg" style="width: 40px; height: 40px;" alt="Atom/RSS Feed" /></a>
        </section>

      </div><!-- main content //-->
    </div>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11067757; 
var sc_invisible=1; 
var sc_security="5e553e07"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="free web stats"
href="http://statcounter.com/free-web-stats/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11067757/0/5e553e07/1/" alt="free
web stats"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
  </body>
</html>
