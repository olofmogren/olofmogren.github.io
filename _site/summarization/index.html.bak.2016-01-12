<html>
  <head>
    <title>Multi-Document Summarization</title>
    <link rel="stylesheet" type="text/css" href="../style.css" />
    <link rel="canonical" href="http://mogren.one/summarization/" />
    <script type="text/javascript">
      function redirectIfAvailable()
      {
        var img = document.body.appendChild(document.createElement("img"));
        img.onload = function()
        {
          //alert('Serving from mogren.one.')
          window.location = 'http://mogren.one/summarization/'
        };
        img.onerror = function()
        {
          //alert('Serving from chalmers.se.')
        };
        img.src = "http://mogren.one/graphics/pixel.gif";
      }
    </script>
  </head>
  <body onload="if(window.location.href.startsWith('http://www.cse')){ redirectIfAvailable(); }">
    <div id="bodydiv" class="container">

    <h1>Extractive Summarization by Aggregating Multiple Similarities</h1>
      <p>
         <img src="../graphics/mogren_summarization.jpg" alt="Extractive Multi-Document Summarization" style="float: right;" />
 
         <span class="bold">Abstract:</span>
News reports, social media streams, blogs, digitized archives and books are part of
a plethora of reading sources that people face every day.
This raises the question of how to best generate automatic summaries.
Many existing methods for extracting summaries rely on comparing the similarity of two sentences in some way.
We present new ways of measuring this similarity, based on sentiment analysis and
continuous vector space representations, and show that combining these
together with similarity measures from existing methods, helps to create better summaries.
The finding is demonstrated with MULTSUM, a novel summarization method that uses
ideas from kernel methods to combine sentence similarity measures. Submodular
optimization is then used to produce summaries that take several different similarity measures into account.
Our method improves over the state-of-the-art on standard benchmark datasets;
it is also fast and scale to large document collections, and the results are statistically significant.
       </p>

       <h2>How to use this.</h2>
       <p>
         We provide our MULTSUM implementation in Python (run without arguments for usage information). The package includes a demo that can be run from command line (see multsum.py), or with an included GUI application (see multsum_gui.py).
       </p>
       <p>
         Download: <a href="MULTSUM.tar.gz">MULTSUM.tar.gz</a>.
       </p>
       <p>
         Github repository: <a href="https://github.com/olofmogren/multsum">https://github.com/olofmogren/multsum</a>.
       </p>
       <!--<p>
         Live demo: <a href="http://mogren.one:9291/">mogren.one:9191</a>.
       </p>//-->
       <p>
         <ul>
           <li>The Python code provided here includes four different similarity measures: LinTFIDF, PositiveSentiment, NegativeSentiment, and Word2Vec.</li>
           <li>To run experiments with the same data, the DUC datasets can be requested from <a href="http://duc.nist.gov/data.html">http://duc.nist.gov/data.html</a>.</li>
           <li>We have also evaluated on the Opinosis dataset (but it's not as prominent in the paper). It can be freely downloaded from <a href="http://kavita-ganesan.com/dataset/">http://kavita-ganesan.com/dataset/</a>.</li>
           <li>To evaluate automatic summaries, ROUGE is the standard tool. For information, and to request a copy of the script, see <a href="http://www.berouge.com/">http://www.berouge.com/</a></li>
           <li>To compare with other systems, Hong et.al. has published a repository of pre-computed summaries for DUC&nbsp;2004. It can be downloaded from <a href="https://cis.upenn.edu/~hongkai1/">https://cis.upenn.edu/~hongkai1/</a>.</li>
         </ul>
       </p>

    <h2>Relevant Publications</h2>
       <p>
          <span class="bold">Extractive Summarization by Aggregating Multiple Similarities</span><br />
          <span class="indent">Fulltext: <a href="mogren2015extractive.pdf">PDF</a>,
          <a href="mogren2015extractive.epub">EPUB</a>.</span><br />
          <span class="publishedin indent"><span class="bold">RANLP 2015, Hissar, Bulgaria, September 6th-11th</span></span><br />
          <span class="authorlist indent"><span class="bold">Authors:</span> Olof Mogren, Mikael K&aring;geb&auml;ck, Devdatt Dubhashi</span>
      </p>
       <p>
          <span class="bold">Extractive Summarization using Continuous Vector Space Models</span><br />
          <span class="bold">Comments:</span> A workshop paper showing preliminary results on multi-document summarization with continuous vector space models for sentence representation. The experiments were performed on opinionated online user reviews.<br />
          <span class="indent">Fulltext: <a href="kageback2014extractive.pdf">PDF</a>.</span><br />
          <span class="publishedin indent"><span class="bold"> 2nd Workshop on Continuous Vector Space Models and their Compositionality CVSC 2014, Gothenburg Sweden </span></span><br />
          <span class="authorlist indent"><span class="bold">Authors:</span> Mikael K&aring;geb&auml;ck, Olof Mogren, Nina Tahmasebi, Devdatt Dubhashi</span>
      </p>
    <br clear="all" />
    <!--<img src="../graphics/mogren_chalmers_web_portrait_155x191.jpg" style="border: 0px solid #999; float: left; margin: 25px; margin-left: 0px;" />//-->

    <a href="http://mogren.one/"><h1 class="grey small">Olof Mogren</h1></a>
    <p class="grey small">PhD Student,<br />
       Department of Computer Science and Engineering,<br />
       Chalmers University of Technology,<br />
       41296 G&ouml;teborg, Sweden</p>

    <h2 class="grey small">Contact</h2>
    <p class="grey small"><span class="bold">Visiting:</span> Room 6447, EDIT building, Campus Johanneberg.</p>
    <p class="grey small"><span class="bold">Email:</span> last name at chalmers.se.</p>
    <p class="grey small"><span class="bold">Telephone:</span> +46-703-969624.</p>

  </div>
  </body>
</html>
