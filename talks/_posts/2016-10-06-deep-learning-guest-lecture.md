---
title: Deep Learning Guest Lecture
layout: talks
tags:
 - default
imgsrc: /graphics/illustrations/2016-10-06/googlenet.svg
imgalt: GoogLeNet (2014), a convolutional network with 22 layers.
longversion: "<p>
A motivational talk about deep artificial neural networks,
given to the students in FFR135 (Artificial neural networks).
I gave motivations for using deep architechtures, and to learn
hierarchical representations for data.
</p>
<p><strong>Reading (web):</strong></p>
<p>
<ul>
<li><a href=\"/blog/2016/08/08/trends-in-neural-machine-translation.html\">My blog post about neural machine translation</a></li>
<li><a href=\"http://deeplearningbook.org\">Deep Learning Book, Goodfellow, Bengio, Courville</a></li>
<li><a href=\"http://playground.tensorflow.org\">playground.tensorflow.org</a></li>
<li><a href=\"http://cs231n.stanford.edu/\">cs231n.stanford.edu</a> - Stanford's course on convnets, with nice browser-based demo!</li>
</ul>
</p>

<p><strong>Reading (publications):</strong></p>
<p>
<ul>
<li>A Fast Learning Algorithm for Deep
Belief Nets; Hinton, Osindero, Tehi; Neural Computation; 2006
<a href=\"https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf\">PDF, cs.toronto.edu</a></li>

<li>Exploring Strategies for Training Deep Neural Networks;
Larochelle, Bengio, Louradour, Lamblin; JMLR 2009
<a href=\"http://www.jmlr.org/papers/v10/larochelle09a.html\">PDF, jmlr.org</a></li>

<li>Imagenet classification with deep convolutional neural networks (&ldquo;AlexNet&rdquo;);
Krizhevsky, Sutskever, Hinton, NIPS 2012;
<a href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\">PDF, cs.toronto.edu</a></li>

<li>Very deep convolutional networks for large-scale image recognition (&ldquo;VGGNet&rdquo;);
Simonyan, Zisserman; 2014;
arXiv 1409.1556;
<a href=\"https://arxiv.org/abs/1409.1556\">PDF, arXiv</a></li>

<li> Going Deeper with Convolutions (&ldquo;GoogLeNet&rdquo;);
Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, Rabinovich; 2014;
arXiv 1409.4842;
<a href=\"https://arxiv.org/abs/1409.4842\">PDF, arXiv</a></li>

<li>Improving neural networks by preventing co-adaptation of feature detectors;
Hinton, Srivastava, Krizhevsky, Sutskever, Salakhutdinov; 2012;
arXiv:1207.0580
<a href=\"http://arxiv.org/abs/1207.0580\">PDF, arXiv</a></li>

<li>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift;
Ioffe, Szegedy;
arXiv:1502.03167
<a href=\"http://arxiv.org/abs/1502.03167\">PDF, arXiv</a></li>

<li>Deep Residual Learning for Image Recognition (&ldquo;ResNet&rdquo;);
He, Zhang, Ren, Sun;
arXiv:1512.03385
<a href=\"http://arxiv.org/abs/1512.03385\">PDF, arXiv</a></li>


<li>The loss surfaces of multilayer networks;
Choromanska, Henaff, Mathieu, Arous, LeCun;
AISTATS 2015
<a href=\"https://arxiv.org/abs/1412.0233\">PDF, arXiv</a></li>


<li>Identifying and attacking the saddle point problem in high-dimensional non-convex optimization;
Dauphin, Pascanu, Gulcehre, Cho, Ganguli, Bengio;
NIPS 2014
<a href=\"http://papers.nips.cc/paper/5486-sparse-pca-via-covariance-thresholding\">PDF, papers.nips.cc</a></li>


<li>Sequence to Sequence Learning with Neural Networks, Ilya Sutskever, Oriol Vinyals, Quoc V. Le. NIPS 2014 <a href=\"http://arxiv.org/abs/1409.3215\">PDF, arXiv</a></li>
<li>Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich and Barry Haddow and Alexandra Birch, ACL 2016: <a href=\"http://aclweb.org/anthology/P/P16/P16-1162.pdf\">PDF, aclweb.org</a><br />
<li>Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, Yonghui Wu et.al. (Google): <a href=\"http://arxiv.org/abs/1609.08144\">PDF, arXiv</a><br />
</ul>
</p>
"

shortversion: "<p>
A motivational talk about deep artificial neural networks,
given to the students in FFR135 (Artificial neural networks).
I gave motivations for using deep architechtures, and to learn
hierarchical representations for data.
</p>"

venue: FFR135, Artificial Neural Networks
authors: Olof Mogren
bibtex: 
permalink:
pdf:
overwriteurl: 
externallink: "http://physics.gu.se/~frtbm/joomla/index.php?option=com_content&view=article&id=115&catid=79&Itemid=290"
---

