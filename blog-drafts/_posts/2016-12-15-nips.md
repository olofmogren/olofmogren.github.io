---
title: NIPS 2016 impressions
layout: blogposts
tags:
 - 
imgsrc: /graphics/illustrations/2016-12-15/nips-cake.png
imgalt: The machine learning cake by Yann LeCunn. It turned into a meme during NIPS 2016.
imgcaption: 

shortversion: Some impressions collected during NIPS 2016 in Barcelona.

venue: 
authors: Olof Mogren
permalink:
pdf: 
overwriteurl: 
---

Last week, the Conference on Neural Information Processing Systems (NIPS)
took place in Barcelona. This was the first time a place outside of north
america was hosting the event, and after growing agressively the last few
years, about 6000 people attended this year's conference.

*Monday* started with tutorials. I attended the *Deep reinforcement learning*
tutorial, by Peter Abbeel and John Schulman, a thorough technical session
mainly about policy optimization, in the introduction of which
Peter Abbeel said that we'll cover the planned topics if we talk
fast enough. This was certainly the case, and I'm happy that I
already knew some of the concepts and ideas from before, something that
I think helped me digest the material much better. The tutorial took place
in one of the smaller rooms, but was still attended by almost 2000 people,
and the two speakers made good use of the three hours, covering techniques
ranging from the
*Cross-entropy method* (Szita, LÃ¶rincz, 2006) [(PDF, psu.edu)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.9726&rep=rep1&type=pdf)
to *Likelihood ratio policy gradient* such as *REINFORCE* (Williams, 1992) [(PDF, springer.com)](http://link.springer.com/content/pdf/10.1007%2FBF00992696.pdf),
and different kinds of variance reduction techniques.

Abbeel concluded the tutorial with some current frontiers,
such as off-policy policy gradients, the utilization of auxilliary objectives,
and policy gradient methods for natural language,
and then went on to announce the all new
[Open AI Universe](https://universe.openai.com/),
a platform for people to try out different RL algorithms on
thousands of different games and web browser interfaces.


TODO: GAN tutorial by Ian Goodfellow. Schmidthubered.

TODO: Rocket AI

*Learning to learn by gradient descent by gradient descent*

*Learning to learn by gradient descent by gradient descent*
not only wins my award for the nicest play on words in the title,
it's also a really nice paper outlining how to use LSTMs to learn
the optimization strategy for an optimization problem.


TODO: meta-learning, RNN symposium.

![OpenAI Universe](/graphics/illustrations/2016-12-15/openai-universe.png)


