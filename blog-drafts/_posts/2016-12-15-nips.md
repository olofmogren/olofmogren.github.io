---
title: NIPS 2016 impressions - unfinished draft
layout: blogposts
tags:
 - 
imgsrc: /graphics/illustrations/2016-12-15/nips-cake.png
imgalt: The machine learning cake by Yann LeCunn. It turned into a meme during NIPS 2016.
imgcaption: 

shortversion: Some impressions collected during NIPS 2016 in Barcelona.

venue: 
authors: Olof Mogren
permalink:
pdf: 
overwriteurl: 
---

In early December, the Conference on Neural Information Processing Systems (NIPS)
took place in Barcelona. This was the second time a place outside of north
america was hosting the event, and after growing agressively the last few
years, about 6.000 people attended this year's conference.

*Monday* started with tutorials. I attended the *Deep reinforcement learning*
tutorial, by Peter Abbeel and John Schulman, a thorough technical session
mainly about policy optimization, in the introduction of which
Peter Abbeel said that we'll cover the planned topics if we talk
fast enough. This was certainly the case, and I'm happy that I
already knew some of the concepts and ideas from before, something that
I think helped me digest the material much better. The tutorial took place
in one of the smaller rooms, but was still attended by almost 2000 people,
and the two speakers made good use of the three hours, covering techniques
ranging from the
*Cross-entropy method* (Szita, LÃ¶rincz, 2006) [(PDF, psu.edu)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.9726&rep=rep1&type=pdf)
to *Likelihood ratio policy gradient* such as *REINFORCE* (Williams, 1992) [(PDF, springer.com)](http://link.springer.com/content/pdf/10.1007%2FBF00992696.pdf),
and different kinds of variance reduction techniques.

![OpenAI Universe](/graphics/illustrations/2016-12-15/openai-universe.png)

Abbeel concluded the tutorial with some current frontiers,
such as off-policy policy gradients, the utilization of auxilliary objectives,
and policy gradient methods for natural language,
and then went on to announce the all new
[Open AI Universe](https://universe.openai.com/),
a platform for people to try out different RL algorithms on
thousands of different games and web browser interfaces.

The *Nuts and Bolts of Building Applications using Deep Learning* tutorial
by Andrew Ng gave some common sense suggestions on how to train and deploy
machine learning models in industry settings. There wasn't much technical
details.

Next up was the GAN tutorial by Ian Goodfellow.
He really made an effort to make the session a real tutorial, engaging
attendees in exercises, dispite having almost filled up the largest
hall, with a capacity of roughly five thousand people.
Schmidthubered.

TODO: Rocket AI

*Learning to learn by gradient descent by gradient descent*

*Learning to learn by gradient descent by gradient descent*
not only wins my award for the nicest play on words in the title,
it's also a really nice paper outlining how to use LSTMs to learn
the optimization strategy for an optimization problem.


TODO: meta-learning, RNN symposium.


