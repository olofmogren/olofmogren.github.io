---
title: ACL 2016 in Berlin
layout: blogposts
tags:
 - NLP
 - ACL
imgsrc: /graphics/illustrations/2016-08-12/acl-logo54.png
imgalt: ACL 2016 in Berlin.
imgcaption: 

venue: 
authors: Olof Mogren
permalink:
pdf: 
overwriteurl: 
---

August 7-12, the 54th conference of the Association of Computational Linguistics (ACL) took place at the Humboldt University in Berlin, along with co-located tutorials and workshops. The conference was attended by roughly 1700 people, and hundreds of papers were presented during the sessions.

In this blog post, I intend to give an overview of some of the noteworthy papers
presented at ACL this year. The selection is based on my own taste,
in combination with my impressions from reading the papers
and attending the presentations. Feel free to give me your views
in the comment section in the bottom of the page.

Also see my blog posts about the [Tutorial on Neural Machine Translation](http://mogren.one/blog/2016/08/08/trends-in-neural-machine-translation.html) and the [First Workshop on Representation Learning for NLP](http://mogren.one/blog/2016/08/11/representation-learning-for-nlp.html).

## Monday

**Generating Factoid Questions with RNNs**, Iulian Vlad Serban; Alberto García-Durán; Caglar Gulcehre; Sungjin Ahn; Sarath Chandar; Aaron Courville; Yoshua Bengio

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1056.pdf)

This paper presents a large corpus of 30 million question-answer pairs,
designed to be used in the development of QA systems. The data is
synthetically created using factoid data from Freebase and a neural
model. The generated questions are evaluated and
compared to questions generated by a template-based method. 

Iulian Serban gave a really nice presentation, illustrating a
somewhat creative solution to an interesting problem.

**Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models**, Minh-Thang Luong and Christopher D. Manning

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1100.pdf)

This paper presents a novel NMT model where out-of-vocabulary words are
treated as a character sequence. The authors report big improvements in BLEU scores
over models that handle OOV words by dictionary lookup, and claim that this
model produces translations with better quality of the OOV translations.

When the system comes across an OOV word, it uses a trained deep LSTM
on character level, always initialized with a zero state.
The final internal state of this character model
is used as the representation for this OOV word.
The reason for the zero initialization is to make the system simple;
the representation of all instances of one OOV word can be precomputed 
before using the word-based model.
The authors show that the embeddings created by the character-based
model are comparable to those learned by a normal word-based model.
This comes as a nice property of the learning; no
explicit learning signal is provided for this to happen.

When the word-based decoder produces an &lt;UNK&gt;, the character based
decoder is used.
The approach is nice, although the paper does not explain why the word-vocabulary
is necessary. If the character-based model can learn embeddings similar
to those learned by the word-model, shouldn't it be possible to 
use a model that works entirely on character level?
(Also see my blog post on
[recent trends in neural machine translation](http://mogren.one/blog/2016/08/08/trends-in-neural-machine-translation.html) ).


**Improving Neural Machine Translation Models with Monolingual Data**, Sennrich, Haddow, and Birch

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1009.pdf)

Neural machine translation models can be viewed as language models
that are conditioned on an input sentence in the source language.
This work suggests that we can enhance the performance of the system,
by feeding it synthetical data. The authors propose to use a monolingual
training-corpus which they translate back from
the target language into the source language (using a baseline
NMT system trained only on parallel data), and then
train the model on this synthetic parallel data, mixed
with real parallel data written by human translators.
The method improves the performance by up to
three BLEU points. They also evaluate using other input
in the encoding part, but without much improvement over the
baseline. The result is interesting, as it allows for a kind of
semi-supervised approach to train NMT systems, and we have
the same conclusion that we are used to with neural models:
having more data is more important than having high-quality data.

**Together we stand: Siamese Networks for Similar Question Retrieval**,
Arpita Das, Harish Yenala, Manoj Chinnakotla, and Manish Shrivastava

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1036.pdf)

The authors propose a convolutional neural network to embed posts
in community question answer systems. The model uses a twin layout
with tied weights and is trained by a contrastive loss function.
They manage to outperform existing methods based on translation models,
topic models, and some neural models.
The proposed method is a rather elegant way of learning similar representations
for semantically similar questions, a reasonable approach to find similar
posts in a discussion forum.



## Tuesday


**Neural Machine Translation of Rare Words with Subword Units**, Rico Sennrich, Barry Haddow, and Alexandra Birch

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1162.pdf)

The authors present a neural machine translation model that works on
subword units to overcome the problem of words that are not part
of the vocabulary. NMT systems struggle with large vocabularies,
and in previous work, the handling of out-of-vocabulary words (OOV)
have been primitive at best. This solution builds a vocabulary using
the [byte-pair encoding (BPE)](https://en.wikipedia.org/wiki/Byte_pair_encoding)
algorithm, segmenting words into n-grams. In the talk, Rico Sennrich
said that it can be viewed as a "character level model working on
compressed character data". This is one of at least three different
papers that work on the problem with rare words in NMT systems
at this years ACL. The model is nice, rare words need no special
treatment after the preprocessing of segmenting the input
data, and they present good results, improving over a baseline
(that handles rare words with a lexicon lookup) with roughly
1 BLEU point.
Also see my blog post on
[recent trends in neural machine translation](http://mogren.one/blog/2016/08/08/trends-in-neural-machine-translation.html).


<figure style="max-width: 40%; float: right;">
<img src="/graphics/illustrations/2016-08-12/hamilton-diachronic-embeddings.png" alt="Meaning of words that change over time." style="max-width: 100%" />
<figcaption>
Two-dimensional visualization of semantic change in English using SGNS vectors. 2 a, The word gay shifted from
meaning “cheerful” or “frolicsome” to referring to homosexuality. b, In the early 20th century broadcast referred to “casting
out seeds”; with the rise of television and radio its meaning shifted to “transmitting signals”. c, Awful underwent a process of
pejoration, as it shifted from meaning “full of awe” to meaning “terrible or appalling” (Simpson et al., 1989).
</figcaption>
</figure>

**Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change**, William Hamilton, Jure Leskovec and Dan Jurfsky

This work presents a nice application to use word embeddings
to track the changes of semantics over time, along with some
interesting observations.


**A Character-Level Decoder without Eplicit Segmentation for Neural Machine Translation**, Junyoung Chung, Kyunghyun Cho, Yoshua Bengio

This paper presents a model trained using subword-units as inputs and a
character sequence as output. The input is segmented using the byte-pair
encoding algorithm
as in Sennrich et.al. 2015.
The character-based decoder outperforms a decoder with subword-units.
Traditionally, translation systems work on word-level, even though a neural
model can suffer from large vocabulary sizes. This is why we see a number
of systems that try to remedy this, initially by subword-level modelling,
but now also on character-level.
(Also see my blog post on
[recent trends in neural machine translation](http://mogren.one/blog/2016/08/08/trends-in-neural-machine-translation.html)).

## Wednesday

<figure style="max-width: 40%; float: right;">
<img src="/graphics/illustrations/2016-08-12/joan-bresnan-lifetime-achievement-award.jpg" alt="Meaning of words that change over time." style="max-width: 100%" />
<figcaption>
Professor Joan Bresnan, giving the acceptance speech at ACL 2016.
</figcaption>
</figure>


**ACL's Lifetime achivement award 2016** was given to linguistics professor Joan Bresnan of Stanford who gave a nice acceptance speech about her transition
from viewing natural language through the lens of formal grammars
to working with probabilistic methods that model linguistic phenomena.
Initially a PhD student under supervision of
Noam Chomskyv [(read more on Wikipedia)](https://en.wikipedia.org/wiki/Noam_Chomsky), she spent the first part of her academic life working
with grammatical formalisms, and in the 1970's she developed a theoretical
formal grammatical framework called
Lexical Functional Grammars, LFG [(read more on Wikipedia)](https://en.wikipedia.org/wiki/Lexical_functional_grammar).
At a point in her career, she had a shock realizing that grammatical
rules may be inconsistent with each other.
With the availability of large amounts of computer-readable texts,
and with inspiration from artificial neural networks and visualizations
of quantitative data, she made
the jump from the garden \[of linguistics\] into the bush
\[of data-driven research\], as she phrased it.
One of the first publications after this transition was
*"Predicting the dative alternation"*
[(PDF, web.stanford.edu)](http://web.stanford.edu/~bresnan/CFI04.pdf).

<figure style="max-width: 40%; float: right; clear: both;">
<img src="/graphics/illustrations/2016-08-12/rl-dialogue.png" alt="Overview of the reinforcement learning system." style="max-width: 100%" />
<figcaption>
Schematic of the system framework. The three main system components dialogue policy,
dialogue embedding creation, and reward modelling based on user feedback.
Illustration from the paper. 
</figcaption>
</figure>

**On-line active reward learning for policy optimization in spoken dialogue systems** (outstanding paper), Su, Gasic, Mrksic, Barahona, Ultes, Vandyke, Wen, Young

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1230.pdf)

In a task-oriented dialogue system, the user has a clearly stated
goal, but training a policy-based system to provide useful responses
requres a viable measure of success.
This paper proposes a dialogue system based
on reinforcement learning where the reward function is learned
jointly with the dialogue policy. The reward function learns
to model how happy the user is with the interaction, and the
policy is used to generate responses.

The learned reward function operates on a fixed sized embedding of
the dialogue computed using
a neural sequence to sequence model with bidirectional
[LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)
units, trained as an autoencoder.

The poliicy optimization gets a small negative reward of -1 for each
turn in the dialogue, and a large positive reward if completion is
successful.
The dialogue success is modelled as a
[Gaussian process (GP)](https://en.wikipedia.org/wiki/Gaussian_process),
and since getting explicit feedback from users can be costly and
time-consuming, users are asked to give such feedback only if the
GP model is uncertain. This feedback (coming from either the GP model,
in the cases when its uncertainty estimate is low, or directly
from the user) is then used as the reinforcement signal for
the policy learning.

Although the policy learning uses a variant of the
[Sarsa algorithm](http://www.cse.unsw.edu.au/~cs9417ml/RL1/algorithms.html),
the paper is a bit thin on details about how the policy is formulated
and how its optimization works. The BiLSTM autoencoder is
merely used to generate embeddings for the dialogue, while one
could imagine building on this and letting the neural model
take care of more of the interesting parts of the solution.
However, the paper is well written, the idea is nice, and
the presentation at ACL was very good!

**Thorough examination of CNN/Daily Mail reading comprehention task** (outstanding paper), Danqi Chen, Jason Bolton, Chris Manning

[PDF, aclweb.org](http://aclweb.org/anthology/P/P16/P16-1223.pdf)

A nice paper showing two approaches to solve the CNN/Daily Mail
reading comprehension task. The authors show that their 
relatively simple baseline system with a feature-based
classifier beats the state-of-the-art system
by more than 5%, and suggest that harder reading comprehension
datasets are required. Interestingly, one day before this presentation,
two related datasets were presented at ACL,
the LAMBADA dataset from Denis Paperno et.al.
[(PDF, aclweb.org)](http://aclweb.org/anthology/P/P16/P16-1144.pdf)
and the WikiReading dataset for language understanding on Wikipedia
from Daniel Hewlett et.al. at
[Google Research](http://research.google.com/)
[(PDF, aclweb.org)](http://aclweb.org/anthology/P/P16/P16-1145.pdf).

The CNN/Daily Mail dataset contains
article text paired with questions based on bullet point
summaries from the source web pages. This paper also presents a neural
system with an attention mechanism, trained to output
an entity token, which beats the baseline with a small margin.
(But recall that the simple baseline beats the previous
state-of-the-art by a large margin)!

The paper is very well written, and the presentation was great.
It's nice to see papers where some work has gone into creating
strong baselines.


**Learning language games through interaction** (outstanding paper), Sida Wang, Percy Liang, Chris Manning

* *Pretty entertaining! Nice presentation*
* Wish list:
  - Interactive learning, adapt to users, handle special domains and low resouce
* Interactive language game.
  - Human player, knows goal, knows language
  - Computer player, does not know the goal, doesnot understaand language
    + need to learn language
* ShrdLURN
  - user writes command.
  - Is given some candidate actions; accepts one.
  - Semantic parsing
    + start from smallest size, score them with a model (log-linear model with features)
    + adagrad
    + features uni, bi, skipgrams, treegrams
* Players on mturk.
* Players adapt, starting to use only one term.
* Learning works fairly well, especially for top players.
* Cooperative communication
* Pragmatics model
  - Pragmatics helps for the top players
* Interactive learning is good for usability.
  - Feedback mechanism -> less likely to be stuck.
  - Should introduce learning to normal usage.
  - Good for low-resource languages
  - Learn from the actual distribution

