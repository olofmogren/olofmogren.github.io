---
layout: default
title: PhD Student Olof Mogren
---
      <section class="research-topic">
        <div class="inner">

          <div class="block block-graphic" style="padding-top: 40px;">
            <p><img src="publications/2016/assisting/rnn-recommendation.png" alt="Illustration" style="margin-top: 30px;" /></p>
          </div>
          <div class="block block-copy half">
<h2>Assisting Discussion Forum Users using Deep Recurrent Neural Networks</h2>
<p>
In this work we present a discussion forum assistant that aims to help
people find their way around a forum and give intelligent
suggestions on where to get the information that they need.
The assistant is based on deep recurrent neural networks (RNNs),
trained to perform three different tasks when faced with a
question from a user. Firstly, to recommend related posts.
Secondly, to recommend other users that might be able to help.
Thirdly, it recommends other channels in the forum
where people may discuss related topics.
</p>
<p><a href="publications/2016/assisting" title="Assisting Discussion Forum Users using Deep Recurrent Neural Networks">Read more.</a></p>
<!--
![Illustration](graphics/mogren_summarization.png)
//-->
          </div>

        </div>
      </section>
      <section class="research-topic">
        <div class="inner">
          <div class="block block-copy half">

<h2>Multi-Document Summarization</h2>
<p>Automatic summarization is the process of presenting the contents of written documents in a short, comprehensive fashion. We define the problem as choosing the most informative sentences from the input documents, while minimizing the redundancy in the summary. This definition calls for a way of measuring the similarity between sentences that captures as much as possible of the meaning. We present novel ways of measuring the similarity between sentences, based on neural word embeddings and sentiment analysis. We also show that combining multiple sentence similarity scores, by multiplicative aggregation, helps in the process of creating better extractive summaries. </p>
<p><a href="summarization" title="Multi-Document Summarization">Read more.</a></p>
<!--
![Illustration](graphics/mogren_summarization.png)
//-->
          </div>

          <div class="block block-graphic" style="padding-top: 40px;">
            <p><img src="graphics/mogren_summarization.png" alt="Illustration" /></p>          </div>
          <div class="block block-copy half">
        </div>
      </section>
      <section class="features">
        <div class="inner">
          <div class="feature-grid">
            <div class="table-row">
              <div class="feature">
<h3>Licentiate Seminar</h3>
<p>On November 20th, 2015 at 10:00, I successfully defended my licentiate thesis titled <br />
<em>&quot;Multi-Document Summarization and Semantic Relatedness&quot;</em>.</p>
<p>Discussion leader was <br />
<a href="http://users.ics.aalto.fi/praiko/" title="Tapani Raiko's web page at aalto.fi">Tapani Raiko from Aalto University</a>.</p>
<p><a href="lic" title="Licentiate Thesis Details">Read more.</a></p>              </div>
              <div class="feature">
<h3>Deep Learning Course</h3>
<p>During period four (March-May 2016), I taught a PhD course in <a href="http://www.cse.chalmers.se/research/lab/courses/deep-learning/">Deep Learning</a>, together with <a href="http://www.kageback.se/">Mikael Kågebäck</a> and <a href="http://www.cse.chalmers.se/~frejohk/">Fredrik Johansson</a>.</p>
<p>The course will cover some of the most important topics in the field, including Convolutional Neural Networks, Recurrent Neural Networks, unsupervised methods, and regularization techniques.</p>
<p>We will use a &quot;flipped classroom&quot; approach, using video lectures from some of the best researchers in the field, along with discussion sessions.</p>
<p><a href="http://www.cse.chalmers.se/research/lab/courses/deep-learning/" title="Deep Learning Course Web Page, chalmers.se">Read more at the course web page.</a></p>              </div>
              <div class="feature">
<h3>Students</h3>
<p>The following students are currently writing their master's theses under my supervision.</p>
<p><strong>Jacob Hagstedt</strong>:<br /> <em>Automatic Discussion Forum Assistant using Recurrent Neural Networks</em>
<br />
<a href="publications/2016/assisting/">Appearing in RepL4NLP</a>.</p>
<p><strong>Sean Pavlov and Simon Almgren</strong>:<br /> <em>Entity Recognition in Swedish Medical Documents</em></p>
<p><strong>Johan Ekdahl and William Axhav Bratt</strong>:<br /> <em>Proactive Intelligent Personal Assistant for a Car Environment</em></p>
<p><a href="students">Read more.</a></p>              </div>
            </div>
          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h3>Recent Talks</h3>
<div style="float: right;"><iframe src="https://calendar.google.com/calendar/embed?height=400&amp;wkst=1&amp;bgcolor=%23FFFFFF&amp;src=l6sjo71d4l4mts81870rpm56ek%40group.calendar.google.com&amp;color=%235229A3&amp;ctz=Europe%2FStockholm&mode=AGENDA&title=Upcoming%20Seminars" style="overflow-x:hidden;overflow-y:hidden; border-width:0" width="300" height="300" frameborder="0" scrolling="no"></iframe></div>
<ul>
<li>
<p>2016-06-07: <strong>Modelling the World with Deep Learning</strong><br />
(<em>Invited Talk, Sigma Smart Developers Society</em>) 
<a href="http://sigmaitc.se/events/sigma-smart-developers-society/">(<em>details</em>)</a>
<br />
An introduction to Deep Artificial Neural Networks and their applications within image recognition, natural language processing, and reinforcement learning.
</p>
</li>
<li>
<p>2016-02-25: <strong>Recognizing Entities and Assisting Discussion Forum Users using Neural Networks</strong><br />
(<em>Presentation, <a href="http://www.meetup.com/machine-learning-gbg/events/228914275/">Machine Learning and Data Science GBG Meetup</a></em>)<br />
Recurrent Neural Networks can model sequences of arbitrary lengths, and have been successfully applied to tasks such as language modelling, machine translation, sequence labelling, and sentiment analysis. In this this talk, I gave an overview of some ongoing research taking place in our group related to the technology. Firstly, a master thesis project in collaboration with the meetup host Findwise, concerning entity recognition in the medical domain in Swedish. Secondly, the effort to build a system to give useful feedback to users in a discussion forum.</p>
</li>
<li>2016-02-18: <strong>Neural Attention Models</strong><br />
(<em>Presentation, <a href="http://www.cse.chalmers.se/research/lab/seminars/">Chalmers Machine Learning Seminars</a></em>)<br />
In artificial neural networks, attention models allow the system to focus on certain parts of the input. This has shown to improve model accuracy in a number of applications. In image caption generation, attention models help to guide the model towards the parts of the image currently of interest. In neural machine translation, the attention mechanism gives the model an alignment of the words between the source sequence and the target sequence.
In this talk, we'll go through the basic ideas and workings of attention models, both for recurrent networks and for convolutional networks. In conclusion, we will see some recent papers that applies attention mechanisms to solve different tasks in natural language processing and computer vision.</li>
</ul>
<p><a href="presentations/">More info and more talks.</a></p>          </div>
        </div>
      </section>
      <section>
        <div class="inner">
          <div class="block block-copy">
<h2>About Me</h2>
<p><img style="float: right;" src="graphics/mogren-mountain-whitebg-cropped-medium.jpg" /> I work as a PhD student in the <a href="http://www.cse.chalmers.se/research/lab/">machine learning research group</a> with problems related to data science and machine learning, using methods from deep learning and graphical models.</p>
<p>I currently teach <a href="http://www.cse.chalmers.se/research/lab/courses/algorithms-for-machine-learning-tda-231/">Algorithms for Machine Learning and Inference</a>. In the past, I have taught the <a href="https://ai-course-tin172-dit410.github.io/">AI course</a>
(specifically the parts about probabilistic methods, including probabilistic graphical models),
Object Oriented Programming, Data Structures, and Algorithms (<a href="http://www.cse.chalmers.se/~ptr/alg.html">basic course</a>, and <a href="http://www.cse.chalmers.se/~huangch/course/advanced_algorithm_2015.html">advanced course</a>).</p>
<p><a href="/about">Read more.</a></p>
          </div>
        </div>
      </section>

{% for post in site.posts %}
      <section>
        <div class="inner">
          <div class="block block-copy">

    {{ post.date | date: "%B %e, %Y" }}
    <a href="{{ post.url }}"><h2>{{ post.title }}</h2></a>
    <p>{{ post.abstract }}</p>
          </div>
        </div>
      </section>

{% endfor %}

