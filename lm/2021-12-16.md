---
layout: default
metatags: "<meta name=\"robots\" content=\"noindex,nofollow\" />"
---
 
Welcome to this week's Learning Machines seminar.

**Title:** Double descent : insights from the random feature model

**Speaker:** Stephane D&#x27;ascoli, 

**Abstract:** In this talk I will present various insights on the double descent curve obtained by considering a solvable model for deep learning: the random feature model. First, I will present a fine-grained bias-variance decomposition and show how the double descent curve can be reconciled with the traditional bias-variance tradeoff. Then, I will show that two different kinds of overfitting, which are often conflated, can give rise to a “double descent” curve, and can actually occur simultaneously, leading to a triple descent curve. Finally, I will extend some of these findings to classification tasks on structured data, showing the impact of the loss function and the role of low-dimensional structures.

**About the speaker:** I’m a Ph.D. student working on deep learning, jointly supervised by Giulio Biroli (ENS Paris) and Levent Sagun (FAIR Paris). My research focuses on understanding how deep neural networks are able to generalize despite being heavily overparametrized. On one hand, I use tools from statistical mechanics to study simple models, and try to understand when and why they overfit. On the other hand, I investigate how different types of inductive biases affect learning, from fully-connected networks to convolutional networks to transformers.

**Location:** This is an online seminar. Connect using Zoom.

**Date:** 2021-12-16 15:00

**Zoom link:** [N/A](N/A)

**Upcoming seminars:**

* 2022-01-13, 15:00: Andrew Jesson, OATML, Oxford Applied and Theoretical Machine Learning Group, **digital and physical: **
* 2022-01-20, 15:00: Jon Nordby, Soundsensing, **digital and physical: **
* 2022-01-27, 15:00: Aleksis Pirinen, RISE, **digital and physical: **
* 2022-02-03, 15:00: Josephine Sullivan, KTH, **digital and physical: **
* All times are in CET.

More information and coming seminars: [https://ri.se/lm-sem](https://ri.se/lm-sem)

-- The Learning Machines Team

