---
layout: default
metatags: "<meta name=\"robots\" content=\"noindex,nofollow\" />"
---
 
Welcome to this week's Learning Machines seminar.

**Title:** SoundStream: an end-to-end neural audio codec

**Speaker:** Neil Zeghidour, Google Brain

**Abstract:** Audio codecs (mp3, Opus), are compression algorithms used whenever one needs to transmit audio, whether when streaming a song or during a conference call. In this talk, I will present SoundStream, a novel neural audio codec that can efficiently compress speech, music and general audio at bitrates normally targeted by speech-tailored codecs. SoundStream relies on a model architecture composed by a fully convolutional encoder/decoder network and a residual vector quantizer, which are trained jointly end-to-end. Training leverages recent advances in text-to-speech and speech enhancement, which combine adversarial and reconstruction losses to allow the generation of high-quality audio content from quantized embeddings. By training with structured dropout applied to quantizer layers, a single model can operate across variable bitrates from 3kbps to 18kbps, with a negligible quality loss when compared with models trained at fixed bitrates. In addition, the model is amenable to a low latency implementation, which supports streamable inference and runs in real time on a smartphone CPU. In subjective evaluations using audio at 24kHz sampling rate, SoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps. Moreover, we are able to perform joint compression and enhancement either at the encoder or at the decoder side with no additional latency, which we demonstrate through background noise suppression for speech.

**About the speaker:** Neil Zeghidour is a Senior Research Scientist at Google Brain in Paris, and teaches automatic speech processing at Ecole Normale Supérieure. He previously graduated with a PhD in Machine Learning from Ecole Normale Superieure in Paris, jointly with Facebook AI Research. His main research interest is to integrate signal processing and deep learning into fully learnable architectures for audio understanding and generation.

**Location:** This is an online seminar. Connect using Zoom.

**Date:** 2022-09-08 15:00

**Zoom link:** [N/A](N/A)

**Upcoming seminars:**

* 2022-09-15, 15:00: Martin Hellkvist, Uppsala University, **digital and physical: **
* 2022-09-22, 15:00: Devis Tuia, Ecole Polytechnique Fédérale de Lausanne (EPFL), **digital and physical: **
* 2022-09-29, 15:00: Jörg Tiedemann, Helsinki University, **digital and physical: **
* 2022-10-13, 15:00: Tomasz Trzcinski, Warsaw University of Technology, Tooploox, IDEAS NCBR, Jagiellonian University, **digital and physical: **
* All times are in CET.

More information and coming seminars: [https://ri.se/lm-sem](https://ri.se/lm-sem)

-- The Learning Machines Team

